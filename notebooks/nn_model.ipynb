{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from pathlib import Path\n",
    "from os.path import dirname, abspath\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Altered to work on cluster ?\n",
    "os.chdir(\"/datasets\" + \"/MaskedFace-Net\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose(\n",
    "    [transforms.Resize((100, 100)),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_val = transforms.Compose(\n",
    "    [transforms.Resize((100, 100)),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskedface_net_train = torchvision.datasets.ImageFolder(\"../MaskedFace-Net/train\", transform=transform_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskedface_net_val = torchvision.datasets.ImageFolder(\"../MaskedFace-Net/validation\", transform=transform_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskedface_net_test = torchvision.datasets.ImageFolder(\"../MaskedFace-Net/holdout\", transform=transform_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_train = torch.utils.data.DataLoader(maskedface_net_train,\n",
    "                                          batch_size=32, #4\n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_val = torch.utils.data.DataLoader(maskedface_net_val,\n",
    "                                             batch_size=32, #4\n",
    "                                             shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_test = torch.utils.data.DataLoader(maskedface_net_test,\n",
    "                                             batch_size=32, #4\n",
    "                                             shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 37500\n",
       "    Root location: ../MaskedFace-Net/train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=(100, 100), interpolation=PIL.Image.BILINEAR)\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
       "           )"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maskedface_net_train\n",
    "\n",
    "#Incorrect provides us the labels, Example: ###_Mask_Mouth_Chin means Mask is present, Mouth and Chin Covered should be labeled\n",
    "#as [1, 1, 1, 0] for Mask, Mouth, Chin, Nose\n",
    "#Notes: [1, 1, 1, 1] suggest correct wear, [1, 1, 1, 0] suggests cover nose!, [0, 0, 0, 0] suggest no mask\n",
    "\n",
    "#Currently 0 is Correct, 1 No Mask, 2 Wrong for labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 100, 100])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maskedface_net_train[0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 3 input image channel, 1 output channels, 3x3 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(3, 1, 3)\n",
    "        self.conv2 = nn.Conv2d(1, 1, 3)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(529, 120) \n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        #print(x.shape)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "    \n",
    "net = Net()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   293] loss: 1.828\n",
      "[1,   586] loss: 0.919\n",
      "[1,   879] loss: 0.159\n",
      "[1,  1172] loss: 0.105\n",
      "[2,   293] loss: 0.100\n",
      "[2,   586] loss: 0.080\n",
      "[2,   879] loss: 0.070\n",
      "[2,  1172] loss: 0.078\n",
      "[3,   293] loss: 0.077\n",
      "[3,   586] loss: 0.073\n",
      "[3,   879] loss: 0.057\n",
      "[3,  1172] loss: 0.055\n",
      "Finished Training\n",
      "CPU times: user 1h 18min 51s, sys: 1min 43s, total: 1h 20min 34s\n",
      "Wall time: 52min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#Takes a while, maybe few hours??\n",
    "batch_g = []\n",
    "ep = []\n",
    "for epoch in range(3):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(data_loader_train):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "            \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 293 == 292:    # print every 293 mini batches [37500/(batch size == 32)/4 (for graphical purposes)]\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 293))\n",
    "            batch_g.append(epoch + 1)\n",
    "            ep.append(running_loss / 293)\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.827519744329485,\n",
       " 0.9193126423977341,\n",
       " 0.15891902907131678,\n",
       " 0.10507100702298379,\n",
       " 0.10026990363863852,\n",
       " 0.08007706070967248,\n",
       " 0.07012985736837311,\n",
       " 0.07754776709150434,\n",
       " 0.07677954363751101,\n",
       " 0.07266101551102315,\n",
       " 0.05659780767865466,\n",
       " 0.05454405135937582]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(batch_g, ep)), columns = ['Epoch', 'Loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The black bar represents the Error or in other words the variability of data\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(data=df, x = \"Epoch\", y = \"Loss\").set_title(\"Loss found when averaging on every 4th Loss recorded per Epoch\")\n",
    "\n",
    "print(\"The black bar represents the Error or in other words the variability of data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test set: 98 %\n"
     ]
    }
   ],
   "source": [
    "#Accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i, data in enumerate(data_loader_val):\n",
    "        inputs, labels = data\n",
    "        outputs = net(inputs)\n",
    "        predicted = labels\n",
    "        total += labels.size(0)\n",
    "        label_tensor_maxs = torch.tensor([torch.argmax(x) for x in outputs]) #Used to be labels\n",
    "        correct += (predicted == label_tensor_maxs).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the validation set: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking through the validation accuracy values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 1, 0, 2, 2, 2, 1, 0, 2, 1, 2, 0, 2, 1, 2, 2, 2, 2, 0, 0, 0, 2,\n",
       "        2, 1, 1, 0, 1])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_tensor_maxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0056)\n",
      "tensor(0.0301)\n",
      "tensor(0.1808)\n",
      "tensor(0.0090)\n",
      "tensor(-0.0284)\n",
      "tensor(0.1535)\n",
      "tensor(0.0553)\n",
      "tensor(0.1972)\n",
      "tensor(0.0754)\n"
     ]
    }
   ],
   "source": [
    "#Labelled as 0\n",
    "for x in outputs[[0, 1, 4, 9, 13, 20, 21, 22, 27]]:\n",
    "    print(x.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.0827)\n",
      "tensor(-0.0227)\n",
      "tensor(-0.0035)\n",
      "tensor(-0.0895)\n",
      "tensor(-0.0400)\n",
      "tensor(-0.0633)\n",
      "tensor(-0.0078)\n",
      "tensor(0.0231)\n"
     ]
    }
   ],
   "source": [
    "#Labelled as 1\n",
    "for x in outputs[[2, 3, 8, 11, 15, 25, 26, 28]]:\n",
    "    print(x.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0345)\n",
      "tensor(0.0505)\n",
      "tensor(0.0570)\n",
      "tensor(0.0893)\n",
      "tensor(0.0634)\n",
      "tensor(0.0416)\n",
      "tensor(0.0248)\n",
      "tensor(0.0117)\n",
      "tensor(0.0459)\n",
      "tensor(0.0349)\n",
      "tensor(0.0484)\n",
      "tensor(0.0454)\n"
     ]
    }
   ],
   "source": [
    "#Labelled as 2\n",
    "for x in outputs[[5, 6, 7, 10, 12, 14, 16, 17, 18, 19, 23, 24]]:\n",
    "    print(x.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
