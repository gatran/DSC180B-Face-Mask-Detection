{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.nn import Dropout\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import dirname, abspath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dirname(dirname(dirname(dirname(dirname(dirname(dirname(dirname(abspath(\"loading_dataset.ipynb\")))))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(d + \"/MaskedFace-Net\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose(\n",
    "    [transforms.RandomRotation(20),\n",
    "     transforms.RandomHorizontalFlip(0.5),\n",
    "     transforms.CenterCrop(300),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_val = transforms.Compose(\n",
    "    [transforms.CenterCrop(300),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskedface_net_train = torchvision.datasets.ImageFolder(\"../MaskedFace-Net/train\", transform=transform_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskedface_net_val = torchvision.datasets.ImageFolder(\"../MaskedFace-Net/validation\", transform=transform_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "maskedface_net_test = torchvision.datasets.ImageFolder(\"../MaskedFace-Net/holdout\", transform=transform_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_train = torch.utils.data.DataLoader(maskedface_net_train,\n",
    "                                          batch_size=4,\n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_val = torch.utils.data.DataLoader(maskedface_net_val,\n",
    "                                             batch_size=4,\n",
    "                                             shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_test = torch.utils.data.DataLoader(maskedface_net_test,\n",
    "                                             batch_size=4,\n",
    "                                             shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[-0.6784, -0.6941, -0.6863,  ...,  0.5451,  0.5529,  0.5451],\n",
       "           [-0.6784, -0.7098, -0.6941,  ...,  0.5765,  0.5843,  0.5608],\n",
       "           [-0.6706, -0.7020, -0.6941,  ...,  0.5686,  0.5843,  0.5922],\n",
       "           ...,\n",
       "           [ 0.2392,  0.2471,  0.2549,  ...,  0.0118,  0.0510,  0.2314],\n",
       "           [ 0.2471,  0.2471,  0.2706,  ...,  0.0980,  0.0353,  0.0745],\n",
       "           [ 0.2784,  0.2549,  0.2706,  ...,  0.3490,  0.2314,  0.0824]],\n",
       " \n",
       "          [[-0.6941, -0.7098, -0.7020,  ...,  0.1843,  0.1765,  0.1765],\n",
       "           [-0.6941, -0.7255, -0.7098,  ...,  0.2000,  0.2078,  0.1843],\n",
       "           [-0.6863, -0.7176, -0.7098,  ...,  0.1922,  0.2078,  0.2000],\n",
       "           ...,\n",
       "           [ 0.6941,  0.7020,  0.7098,  ...,  0.4196,  0.4039,  0.3882],\n",
       "           [ 0.7020,  0.7020,  0.7255,  ...,  0.4353,  0.3647,  0.3725],\n",
       "           [ 0.7333,  0.7098,  0.7255,  ...,  0.4745,  0.4118,  0.4196]],\n",
       " \n",
       "          [[-0.7961, -0.8118, -0.7961,  ...,  0.0667,  0.0667,  0.0510],\n",
       "           [-0.7961, -0.8196, -0.8039,  ...,  0.1059,  0.1137,  0.0745],\n",
       "           [-0.7882, -0.8118, -0.8039,  ...,  0.1137,  0.1137,  0.1137],\n",
       "           ...,\n",
       "           [ 0.8667,  0.8745,  0.8824,  ...,  0.5843,  0.5686,  0.5765],\n",
       "           [ 0.8588,  0.8588,  0.8824,  ...,  0.5843,  0.5373,  0.5529],\n",
       "           [ 0.8902,  0.8667,  0.8824,  ...,  0.6000,  0.5529,  0.5529]]],\n",
       " \n",
       " \n",
       "         [[[ 0.6471,  0.6784,  0.7569,  ...,  0.4667,  0.4667,  0.4667],\n",
       "           [ 0.7020,  0.6941,  0.7098,  ...,  0.4667,  0.4667,  0.4667],\n",
       "           [ 0.7255,  0.6863,  0.6941,  ...,  0.4588,  0.4588,  0.4667],\n",
       "           ...,\n",
       "           [ 0.6314,  0.6314,  0.6235,  ...,  0.7176,  0.7176,  0.7176],\n",
       "           [ 0.6235,  0.6235,  0.6314,  ...,  0.7176,  0.7176,  0.7176],\n",
       "           [ 0.6235,  0.6157,  0.6157,  ...,  0.7176,  0.7176,  0.7176]],\n",
       " \n",
       "          [[ 0.1765,  0.1765,  0.2235,  ...,  0.2000,  0.2000,  0.2000],\n",
       "           [ 0.2078,  0.1765,  0.1765,  ...,  0.2000,  0.2000,  0.2000],\n",
       "           [ 0.2471,  0.1686,  0.1765,  ...,  0.1922,  0.2078,  0.2157],\n",
       "           ...,\n",
       "           [ 0.3804,  0.3804,  0.3882,  ...,  0.4588,  0.4588,  0.4588],\n",
       "           [ 0.3725,  0.3882,  0.3961,  ...,  0.4588,  0.4588,  0.4588],\n",
       "           [ 0.3725,  0.3804,  0.3804,  ...,  0.4588,  0.4588,  0.4588]],\n",
       " \n",
       "          [[-0.3961, -0.4039, -0.3490,  ...,  0.1216,  0.1216,  0.1216],\n",
       "           [-0.3961, -0.4353, -0.4118,  ...,  0.1216,  0.1216,  0.1216],\n",
       "           [-0.3804, -0.4431, -0.4353,  ...,  0.1137,  0.1216,  0.1294],\n",
       "           ...,\n",
       "           [ 0.2784,  0.2941,  0.3020,  ...,  0.3412,  0.3255,  0.3255],\n",
       "           [ 0.2863,  0.3020,  0.3098,  ...,  0.3412,  0.3255,  0.3255],\n",
       "           [ 0.2863,  0.2941,  0.2941,  ...,  0.3255,  0.3255,  0.3255]]],\n",
       " \n",
       " \n",
       "         [[[ 0.3804,  0.3882,  0.3490,  ...,  0.9294,  0.8980,  0.9216],\n",
       "           [ 0.3098,  0.3882,  0.3804,  ...,  0.9529,  0.9373,  0.9373],\n",
       "           [ 0.3333,  0.3961,  0.3961,  ...,  0.9529,  0.9529,  0.9608],\n",
       "           ...,\n",
       "           [ 0.1922,  0.1843,  0.1529,  ...,  0.6706,  0.6706,  0.6549],\n",
       "           [ 0.2078,  0.2078,  0.1529,  ...,  0.6706,  0.6784,  0.6706],\n",
       "           [ 0.2078,  0.2157,  0.1765,  ...,  0.6627,  0.6784,  0.6706]],\n",
       " \n",
       "          [[ 0.0275,  0.0353, -0.0118,  ...,  0.4588,  0.4275,  0.4510],\n",
       "           [-0.0431,  0.0353,  0.0275,  ...,  0.4667,  0.4667,  0.4667],\n",
       "           [-0.0196,  0.0275,  0.0275,  ...,  0.4667,  0.4667,  0.4745],\n",
       "           ...,\n",
       "           [ 0.6627,  0.6549,  0.6235,  ...,  0.8745,  0.8745,  0.8745],\n",
       "           [ 0.6784,  0.6784,  0.6235,  ...,  0.8510,  0.8588,  0.8745],\n",
       "           [ 0.6784,  0.6863,  0.6471,  ...,  0.8510,  0.8588,  0.8510]],\n",
       " \n",
       "          [[-0.2000, -0.1922, -0.2157,  ...,  0.2392,  0.2078,  0.2314],\n",
       "           [-0.2706, -0.1922, -0.2000,  ...,  0.2706,  0.2627,  0.2627],\n",
       "           [-0.2471, -0.1922, -0.1922,  ...,  0.2706,  0.2706,  0.2941],\n",
       "           ...,\n",
       "           [ 0.8824,  0.8745,  0.8431,  ...,  0.9765,  0.9765,  0.9843],\n",
       "           [ 0.8824,  0.8824,  0.8431,  ...,  0.9608,  0.9686,  0.9922],\n",
       "           [ 0.8824,  0.8902,  0.8510,  ...,  0.9451,  0.9686,  0.9765]]],\n",
       " \n",
       " \n",
       "         [[[ 0.7569,  0.7647,  0.7725,  ...,  0.3647,  0.3961,  0.3569],\n",
       "           [ 0.7882,  0.7961,  0.7804,  ...,  0.3725,  0.3804,  0.3412],\n",
       "           [ 0.8431,  0.8275,  0.7961,  ...,  0.3490,  0.3490,  0.3255],\n",
       "           ...,\n",
       "           [ 0.8196,  0.8431,  0.8275,  ...,  0.5373,  0.5059,  0.5059],\n",
       "           [ 0.8275,  0.8510,  0.8510,  ...,  0.5529,  0.5216,  0.5059],\n",
       "           [ 0.8196,  0.8275,  0.8431,  ...,  0.6000,  0.5765,  0.5451]],\n",
       " \n",
       "          [[ 0.2392,  0.2627,  0.2784,  ..., -0.0824, -0.0510, -0.0745],\n",
       "           [ 0.2863,  0.2941,  0.2863,  ..., -0.0824, -0.0667, -0.0902],\n",
       "           [ 0.3490,  0.3333,  0.3020,  ..., -0.0902, -0.0902, -0.1137],\n",
       "           ...,\n",
       "           [ 0.2392,  0.2627,  0.2314,  ..., -0.0431, -0.0353, -0.0353],\n",
       "           [ 0.2627,  0.2706,  0.2549,  ...,  0.0118, -0.0039, -0.0039],\n",
       "           [ 0.2549,  0.2471,  0.2627,  ...,  0.0510,  0.0510,  0.0353]],\n",
       " \n",
       "          [[-0.0353, -0.0196,  0.0039,  ..., -0.2941, -0.2784, -0.3098],\n",
       "           [ 0.0118,  0.0196,  0.0118,  ..., -0.2706, -0.2784, -0.3255],\n",
       "           [ 0.0745,  0.0588,  0.0431,  ..., -0.2863, -0.3020, -0.3255],\n",
       "           ...,\n",
       "           [ 0.0431,  0.0667,  0.0275,  ..., -0.2706, -0.2627, -0.2627],\n",
       "           [ 0.0667,  0.0745,  0.0510,  ..., -0.2157, -0.2314, -0.2392],\n",
       "           [ 0.0588,  0.0510,  0.0510,  ..., -0.1529, -0.1608, -0.2000]]]]),\n",
       " tensor([1, 2, 0, 2])]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iter(data_loader_train).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resnet():\n",
    "    input_img = Input((4, 4, 300,28),name='input_layer')\n",
    "    zeroPad1 = ZeroPadding2D((1,1), name='zeroPad1', dim_ordering='th')\n",
    "    zeroPad1_2 = ZeroPadding2D((1,1), name='zeroPad1_2', dim_ordering='th')\n",
    "    layer1 = Convolution2D(6, 3, 3, subsample=(2, 2), init='he_uniform', name='major_conv', dim_ordering='th')\n",
    "    layer1_2 = Convolution2D(16, 3, 3, subsample=(2, 2), init='he_uniform', name='major_conv2', dim_ordering='th')\n",
    "    zeroPad2 = ZeroPadding2D((1,1), name='zeroPad2', dim_ordering='th')\n",
    "    zeroPad2_2 = ZeroPadding2D((1,1), name='zeroPad2_2', dim_ordering='th')\n",
    "    layer2 = Convolution2D(6, 3, 3, subsample=(1,1), init='he_uniform', name='l1_conv', dim_ordering='th')\n",
    "    layer2_2 = Convolution2D(16, 3, 3, subsample=(1,1), init='he_uniform', name='l1_conv2', dim_ordering='th')\n",
    "    zeroPad3 = ZeroPadding2D((1,1), name='zeroPad3', dim_ordering='th')\n",
    "    zeroPad3_2 = ZeroPadding2D((1,1), name='zeroPad3_2', dim_ordering='th')\n",
    "    layer3 = Convolution2D(6, 3, 3, subsample=(1, 1), init='he_uniform', name='l2_conv', dim_ordering='th')\n",
    "    layer3_2 = Convolution2D(16, 3, 3, subsample=(1, 1), init='he_uniform', name='l2_conv2', dim_ordering='th')\n",
    "    layer4 = Dense(64, activation='relu', init='he_uniform', name='dense1')\n",
    "    layer5 = Dense(16, activation='relu', init='he_uniform', name='dense2')\n",
    "    final = Dense(10, activation='softmax', init='he_uniform', name='classifier')\n",
    "    \n",
    "    sgd = SGD(decay=0., lr=0.01, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss=scc, optimizer=sgd, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        model_ft = models.resnet18(pretrained=True)\n",
    "        set_parameter_requires_grad(model_ft, True)\n",
    "        self.features = nn.Sequential(\n",
    "            *list(model_ft.children())[:6]\n",
    "        )\n",
    "        self.conv1 = nn.Conv2d(in_channels = 128, out_channels = 128, kernel_size = 3)\n",
    "        self.conv2 = nn.Conv2d(in_channels = 128, out_channels = 128, kernel_size = 3)\n",
    "        self.conv3 = nn.Conv2d(in_channels = 128, out_channels = 64, kernel_size = 3)\n",
    "        self.conv4 = nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3)\n",
    "        self.bh1 = nn.BatchNorm2d(num_features = 128)\n",
    "        self.bh2 = nn.BatchNorm2d(num_features = 64)\n",
    "        self.maxpool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = Dropout(p = 0.5)\n",
    "        self.bh3 = nn.BatchNorm1d(num_features = 500)\n",
    "        self.lin1 = nn.Linear(in_features = 2304, out_features =500)\n",
    "        self.lin2 = nn.Linear(in_features = 500, out_features = 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.bh1(F.relu(self.conv1(x)))\n",
    "        x = self.maxpool(x)\n",
    "        x = self.bh1(F.relu(self.conv2(x)))\n",
    "        x = self.bh2(F.relu(self.conv3(x)))\n",
    "        x = self.bh2(F.relu(self.conv4(x)))\n",
    "        x = self.maxpool(x)\n",
    "        x = torch.flatten(x, start_dim = 1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.bh3(F.relu(self.lin1(x)))\n",
    "        x = self.lin2(x)  \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /tmp/xdg-cache/torch/checkpoints/resnet18-5c106cde.pth\n",
      "100%|██████████| 44.7M/44.7M [00:01<00:00, 25.0MB/s]\n"
     ]
    }
   ],
   "source": [
    "model = CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'parameters' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-109-a3f48f9a9629>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"learning_rate\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'parameters' is not defined"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr= parameters[\"learning_rate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(num_epochs, model, optimizer, criterion, train_loader, validation_loader, batch_size, device, save_path):\n",
    "    train_acc_lst = []\n",
    "    train_loss_lst = []\n",
    "    val_acc_lst = []\n",
    "    val_loss_lst = []\n",
    "    val_min_loss = np.inf\n",
    "    \n",
    "    model = model.double().to(device)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-' * 10)\n",
    "        train_loss = 0.0\n",
    "        val_loss = 0.0\n",
    "\n",
    "    #training step(we only update the model in the training loop)\n",
    "        for i, data in enumerate(tqdm(train_loader), 0):\n",
    "            train_inputs, train_labels = data\n",
    "            train_inputs, train_labels = train_inputs.double().to(device), train_labels.double().view(-1, 1).to(device)\n",
    "\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            train_outputs = model(train_inputs)\n",
    "            loss = criterion(train_outputs, train_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            #calculate training loss\n",
    "            train_loss += loss.item() * train_inputs.size(0)\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        for i, data in enumerate(tqdm(validation_loader), 0):\n",
    "            val_inputs, val_labels = data\n",
    "            val_inputs, val_labels = val_inputs.double().to(device), val_labels.double().view(-1, 1).to(device)\n",
    "\n",
    "            val_outputs = model(val_inputs)\n",
    "            loss = criterion(val_outputs, val_labels)\n",
    "            val_loss += loss.item() * val_inputs.size(0)\n",
    "\n",
    "        avg_train_loss = train_loss / (len(train_loader) * batch_size)\n",
    "        train_acc = (torch.sigmoid(train_outputs).squeeze().round() == train_labels.squeeze()).cpu().numpy().mean()\n",
    "\n",
    "        avg_val_loss = val_loss / (len(validation_loader) * batch_size)\n",
    "        val_acc = (torch.sigmoid(val_outputs).squeeze().round() == val_labels.squeeze()).cpu().numpy().mean()\n",
    "\n",
    "\n",
    "        print(\"Epoch: {}/{}...\".format(epoch+1, num_epochs),\n",
    "              \"train Loss: {:.6f}...\".format(avg_train_loss),\n",
    "              \"train accurcy: {:.2f}...\".format(train_acc),\n",
    "              \"val Loss: {:.6f}\".format(avg_val_loss),\n",
    "              \"val accurcy: {:.2f}...\".format(val_acc))\n",
    "\n",
    "        train_loss_lst.append(avg_train_loss)\n",
    "        train_acc_lst.append(round(train_acc, 2))\n",
    "        val_loss_lst.append(avg_val_loss)\n",
    "        val_acc_lst.append(round(val_acc, 2))\n",
    "\n",
    "        if avg_val_loss <= val_min_loss:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "            val_min_loss,\n",
    "            avg_val_loss))\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            val_min_loss = avg_val_loss\n",
    "\n",
    "\n",
    "        model.train()\n",
    "    \n",
    "    return train_acc_lst, train_loss_lst, val_acc_lst, val_loss_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss, train_acc, val_loss, val_acc = training(num_epochs, model, optimizer, criterion, train_loader, validation_loader, batch_size, device, save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
